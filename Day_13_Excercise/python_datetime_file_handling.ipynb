{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’» Python Datetime Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Get the current day, month, year, hour, minute and timestamp from datetime module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day = 17\n",
      "Month = 1\n",
      "Year = 2025\n",
      "Hour = 11\n",
      "Minute = 33\n",
      "Second = 44\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.today()\n",
    "\n",
    "day = now.day\n",
    "month = now.month\n",
    "year = now.year\n",
    "hour = now.hour\n",
    "minute = now.minute\n",
    "second = now.second\n",
    "print(f'Day = {day}')\n",
    "print(f'Month = {month}')\n",
    "print(f'Year = {year}')\n",
    "print(f'Hour = {hour}')\n",
    "print(f'Minute = {minute}')\n",
    "print(f'Second = {second}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Format the current date using this format: \"%m/%d/%Y, %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"01/17/2025, 11:33:44\"\n"
     ]
    }
   ],
   "source": [
    "formated_datetime =  now.strftime('\"%m/%d/%Y, %H:%M:%S\"')\n",
    "print(formated_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Today is 5 December, 2019. Change this time string to time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "today = '15 January, 2025'\n",
    "\n",
    "today = datetime.strptime(today,'%d %B, %Y')\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Calculate the time difference between now and new year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 348 days from the current date to next year\n"
     ]
    }
   ],
   "source": [
    "now = datetime.today()\n",
    "next_year = datetime(2026,1,1,0,0,0)\n",
    "\n",
    "days_to_next_year = next_year - now\n",
    "\n",
    "print('There are {} days from the current date to next year'.format(days_to_next_year.days))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Calculate the time difference between 1 January 1970 and now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Difference is 20105 days, 11:33:45.489994\n"
     ]
    }
   ],
   "source": [
    "past_date = datetime(1970,1,1,0,0,0)\n",
    "today = datetime.today()\n",
    "\n",
    "print('The Difference is {}'.format(today-past_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Think, what can you use the datetime module for? Examples:\n",
    "    - Time series analysis\n",
    "    - To get a timestamp of any activities in an application\n",
    "    - Adding posts on a blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ’» File Handling Exercises:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write a function which count number of lines and number of words in a text. All the files are in the data the folder: a) Read obama_speech.txt file and count number of lines and words b) Read michelle_obama_speech.txt file and count number of lines and words c) Read donald_speech.txt file and count number of lines and words d) Read melina_trump_speech.txt file and count number of lines and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Obama Speech has 66 lines and 2400 words\n",
      "The Michelle Obama Speech has 83 lines and 2204 words\n",
      "The Donald Speech has 48 lines and 1259 words\n",
      "The Melina Trump Speech has 33 lines and 1375 words\n"
     ]
    }
   ],
   "source": [
    "def txt_line_word_counter(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file_obj:\n",
    "            text = file_obj.read()\n",
    "            num_words = len(text.split())\n",
    "        with open(filename, 'r') as file_obj:\n",
    "            text = file_obj.readlines()\n",
    "            num_lines = len(text)\n",
    "    except Exception as e:\n",
    "        num_lines = None\n",
    "        num_words = None\n",
    "        print(e)\n",
    "    return num_lines, num_words\n",
    "\n",
    "n_lines, n_words = txt_line_word_counter('obama_speech.txt')\n",
    "\n",
    "print('The Obama Speech has {} lines and {} words'.format(n_lines,n_words))\n",
    "\n",
    "n_lines, n_words = txt_line_word_counter('michelle_obama_speech.txt')\n",
    "\n",
    "print('The Michelle Obama Speech has {} lines and {} words'.format(n_lines,n_words))\n",
    "\n",
    "n_lines, n_words = txt_line_word_counter('donald_speech.txt')\n",
    "\n",
    "print('The Donald Speech has {} lines and {} words'.format(n_lines,n_words))\n",
    "\n",
    "n_lines, n_words = txt_line_word_counter('melina_trump_speech.txt')\n",
    "\n",
    "print('The Melina Trump Speech has {} lines and {} words'.format(n_lines,n_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('English', 91), ('French', 45), ('Arabic', 25), ('Spanish', 24), ('Portuguese', 9), ('Russian', 9), ('Dutch', 8), ('German', 7), ('Chinese', 5), ('Serbian', 4)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def most_spoken_languages(filename,num_countries):\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        file = open(filename,'r')\n",
    "        country_data = json.load(file)\n",
    "        file.close()\n",
    "\n",
    "        languages = []\n",
    "\n",
    "        for country in country_data:\n",
    "            languages.extend(country[\"languages\"])\n",
    "\n",
    "\n",
    "        languages_count = {}\n",
    "\n",
    "        for language in languages:\n",
    "            if language in languages_count:\n",
    "                languages_count[language] += 1\n",
    "            else:\n",
    "                languages_count[language] = 1\n",
    "\n",
    "        sorted_lannguages = dict(sorted(languages_count.items(), key = lambda item: item[1], reverse=True))\n",
    "\n",
    "        sorted_countries = list(sorted_lannguages.items())[:num_countries] \n",
    "    else:\n",
    "        print(\"Check Your file path, it Does not Exist!\")\n",
    "        sorted_countries = None\n",
    "    \n",
    "    return sorted_countries\n",
    "\n",
    "sort_c = most_spoken_languages('countries_data.json',10)\n",
    "print(sort_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('China', 1377422166), ('India', 1295210000), ('United States of America', 323947000), ('Indonesia', 258705000), ('Brazil', 206135893), ('Pakistan', 194125062), ('Nigeria', 186988000), ('Bangladesh', 161006790), ('Russian Federation', 146599183), ('Japan', 126960000)]\n"
     ]
    }
   ],
   "source": [
    "def most_populated_countries(filename,num_countries):\n",
    "    if os.path.exists(filename):\n",
    "        file = open(filename,'r')\n",
    "        country_data = json.load(file)\n",
    "        country_population = {}\n",
    "\n",
    "        for country in country_data:\n",
    "            country_population[country[\"name\"]] = country[\"population\"]\n",
    "\n",
    "        country_population = dict(sorted(country_population.items(), key=lambda item: item[1], reverse=True))\n",
    "        \n",
    "        country_population = list(country_population.items())[:num_countries]\n",
    "    else:\n",
    "        print(\"file path does not exist!\")\n",
    "        country_population = None\n",
    "    return country_population\n",
    "\n",
    "most_p_c = most_populated_countries('countries_data.json',10)\n",
    "\n",
    "print(most_p_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"obama_speech.txt\",'r')\n",
    "text = file.read()\n",
    "text2 = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Extract all incoming email addresses as a list from the email_exchange_big.txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stephen.marquard@uct.ac.za', 'postmaster@collab.sakaiproject.org', '200801051412.m05ECIaH010327@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'stephen.marquard@uct.ac.za', 'source@collab.sakaiproject.org', 'stephen.marquard@uct.ac.za', 'stephen.marquard@uct.ac.za', 'louis@media.berkeley.edu', 'postmaster@collab.sakaiproject.org', '200801042308.m04N8v6O008125@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'louis@media.berkeley.edu', 'source@collab.sakaiproject.org', 'louis@media.berkeley.edu', 'louis@media.berkeley.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject.org', '200801042109.m04L92hb007923@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'zqian@umich.edu', 'rjlowe@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801042044.m04Kiem3007881@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'rjlowe@iupui.edu', 'source@collab.sakaiproject.org', 'rjlowe@iupui.edu', 'rjlowe@iupui.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject.org', '200801042001.m04K1cO0007738@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'zqian@umich.edu', 'zqian@umich.edu', 'rjlowe@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801041948.m04JmdwO007705@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'rjlowe@iupui.edu', 'source@collab.sakaiproject.org', 'rjlowe@iupui.edu', 'rjlowe@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801041635.m04GZQGZ007313@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'cwen@iupui.edu', 'hu2@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801041633.m04GX6eG007292@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'cwen@iupui.edu', 'hu2@iupui.edu', 'gsilver@umich.edu', 'postmaster@collab.sakaiproject.org', '200801041611.m04GB1Lb007221@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'gsilver@umich.edu', 'source@collab.sakaiproject.org', 'gsilver@umich.edu', 'gsilver@umich.edu', 'gsilver@umich.edu', 'postmaster@collab.sakaiproject.org', '200801041610.m04GA5KP007209@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'gsilver@umich.edu', 'source@collab.sakaiproject.org', 'gsilver@umich.edu', 'gsilver@umich.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject.org', '200801041609.m04G9EuX007197@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'zqian@umich.edu', 'gsilver@umich.edu', 'postmaster@collab.sakaiproject.org', '200801041608.m04G8d7w007184@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'gsilver@umich.edu', 'source@collab.sakaiproject.org', 'gsilver@umich.edu', 'gsilver@umich.edu', 'wagnermr@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801041537.m04Fb6Ci007092@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'wagnermr@iupui.edu', 'source@collab.sakaiproject.org', 'wagnermr@iupui.edu', 'wagnermr@iupui.edu', 'zqian@umich.edu', 'postmaster@collab.sakaiproject.org', '200801041515.m04FFv42007050@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'source@collab.sakaiproject.org', 'zqian@umich.edu', 'zqian@umich.edu', 'antranig@caret.cam.ac.uk', 'postmaster@collab.sakaiproject.org', '200801041502.m04F21Jo007031@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'antranig@caret.cam.ac.uk', 'source@collab.sakaiproject.org', 'antranig@caret.cam.ac.uk', 'antranig@caret.cam.ac.uk', 'gopal.ramasammycook@gmail.com', 'postmaster@collab.sakaiproject.org', '200801041403.m04E3psW006926@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'gopal.ramasammycook@gmail.com', 'source@collab.sakaiproject.org', 'gopal.ramasammycook@gmail.com', 'gopal.ramasammycook@gmail.com', 'david.horwitz@uct.ac.za', 'postmaster@collab.sakaiproject.org', '200801041200.m04C0gfK006793@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'postmaster@collab.sakaiproject.org', '200801041106.m04B6lK3006677@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'postmaster@collab.sakaiproject.org', '200801040947.m049lUxo006517@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'josrodri@iupui.edu', 'david.horwitz@uct.ac.za', 'postmaster@collab.sakaiproject.org', '200801040932.m049W2i5006493@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'source@collab.sakaiproject.org', 'david.horwitz@uct.ac.za', 'david.horwitz@uct.ac.za', 'josrodri@iupui.edu', 'stephen.marquard@uct.ac.za', 'postmaster@collab.sakaiproject.org', '200801040905.m0495rWB006420@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'stephen.marquard@uct.ac.za', 'source@collab.sakaiproject.org', 'stephen.marquard@uct.ac.za', 'stephen.marquard@uct.ac.za', 'louis@media.berkeley.edu', 'postmaster@collab.sakaiproject.org', '200801040023.m040NpCc005473@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'louis@media.berkeley.edu', 'source@collab.sakaiproject.org', 'louis@media.berkeley.edu', 'louis@media.berkeley.edu', 'louis@media.berkeley.edu', 'postmaster@collab.sakaiproject.org', '200801032216.m03MGhDa005292@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'louis@media.berkeley.edu', 'source@collab.sakaiproject.org', 'louis@media.berkeley.edu', 'louis@media.berkeley.edu', 'ray@media.berkeley.edu', 'postmaster@collab.sakaiproject.org', '200801032205.m03M5Ea7005273@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'ray@media.berkeley.edu', 'source@collab.sakaiproject.org', 'ray@media.berkeley.edu', 'ray@media.berkeley.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801032133.m03LX3gG005191@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'cwen@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801032127.m03LRUqH005177@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'cwen@iupui.edu', 'wagnermr@iupui.edu', 'cwen@iupui.edu', 'postmaster@collab.sakaiproject.org', '200801032122.m03LMFo4005148@nakamura.uits.iupui.edu', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'source@collab.sakaiproject.org', 'cwen@iupui.edu', 'cwen@iupui.edu', 'wagnermr@iupui.edu']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('email_exchange_big.txt', 'r') as f_obj:\n",
    "    text = f_obj.read()\n",
    "\n",
    "pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}' # <--- credit ChatGpt\n",
    "\n",
    "matches = re.findall(pattern,text)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 120), ('and', 107), ('of', 81), ('to', 66), ('our', 58), ('we', 50), ('a', 48), ('that', 47), ('is', 36), ('in', 22)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_most_common_words(filename,num_words):\n",
    "    pattern = r'[\\-â€“â€”]'\n",
    "    words_dict = {}\n",
    "    try:\n",
    "        with open(filename) as file_obj:\n",
    "            text = file_obj.read()\n",
    "            text = re.sub(pattern, '',text)\n",
    "            word_list = text.split()\n",
    "            for word in word_list:\n",
    "                if word in words_dict:\n",
    "                    words_dict[word] += 1\n",
    "                else:\n",
    "                    words_dict[word] = 1\n",
    "    except FileNotFoundError:\n",
    "        print('Sorry file does not exist')\n",
    "        return None\n",
    "   \n",
    "    sorted_dict_val_list = dict(sorted(words_dict.items(), key=lambda val: val[1], reverse=True))\n",
    "    return list(sorted_dict_val_list.items())[:num_words]\n",
    "\n",
    "x = find_most_common_words('obama_speech.txt',10)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Use the function, find_most_frequent_words to find: a) The ten most frequent words used in Obama's speech b) The ten most frequent words used in Michelle's speech c) The ten most frequent words used in Trump's speech d) The ten most frequent words used in Melina's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama = [('the', 120), ('and', 107), ('of', 81), ('to', 66), ('our', 58), ('we', 50), ('a', 48), ('that', 47), ('is', 36), ('in', 22)]\n",
      "Michelle = [('to', 83), ('and', 80), ('the', 78), ('of', 46), ('a', 41), ('that', 40), ('in', 36), ('our', 27), ('for', 26), ('my', 26)]\n",
      "Trump = [('the', 61), ('and', 53), ('will', 40), ('of', 38), ('to', 32), ('our', 30), ('we', 26), ('is', 20), ('We', 15), ('America', 14)]\n",
      "Melina = [('and', 73), ('to', 54), ('the', 48), ('I', 28), ('is', 28), ('for', 27), ('of', 25), ('a', 22), ('that', 19), ('Donald', 17)]\n"
     ]
    }
   ],
   "source": [
    "obama = find_most_common_words('obama_speech.txt',10)\n",
    "print(f'Obama = {obama}')\n",
    "michelle = find_most_common_words('michelle_obama_speech.txt',10)\n",
    "print(f'Michelle = {michelle}')\n",
    "trump = find_most_common_words('donald_speech.txt',10)\n",
    "print(f'Trump = {trump}')\n",
    "melina = find_most_common_words('melina_trump_speech.txt',10)\n",
    "print(f'Melina = {melina}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Write a python application that checks similarity between two texts. It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. For instance check the similarity between the transcripts of Michelle's and Melina's speech. You may need a couple of functions, function to clean the text(clean_text), function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). List of stop words are in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stops_words import stop_words\n",
    "\n",
    "def clean_text(text):\n",
    "    pattern = r'[%$@&#;!\\nâ€“-]'\n",
    "    return re.sub(pattern,'',text)\n",
    "\n",
    "def remove_support_words(words_list):\n",
    "    stop_words_list = stop_words\n",
    "    return [word.lower() for word in words_list if word.lower() not in stop_words_list and word != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump and Obama speech has similarity score of 9.15%\n",
      "Obama and Obama speech has similarity score of 100.0%\n"
     ]
    }
   ],
   "source": [
    "def similarity(filepath_1,filepath_2):\n",
    "    try:\n",
    "        with open(filepath_1) as f_obj:\n",
    "            text_1 = f_obj.read()\n",
    "        with open(filepath_2) as f_obj:\n",
    "            text_2 = f_obj.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"File Path not found!\")\n",
    "        return None\n",
    "    \n",
    "    cleaned_text_1 = clean_text(text_1)\n",
    "    cleaned_text_2 = clean_text(text_2)\n",
    "\n",
    "    unique_no_support_1 = set(remove_support_words(cleaned_text_1.split()))\n",
    "\n",
    "    unique_no_support_2 = set(remove_support_words(cleaned_text_2.split()))\n",
    "\n",
    "    similar_words = [word for word in unique_no_support_1 if word in unique_no_support_2]\n",
    "\n",
    "    all_word_list =  unique_no_support_1.union(unique_no_support_2)\n",
    "\n",
    "    percent_score = (len(similar_words) / len(all_word_list)) * 100\n",
    "\n",
    "    \n",
    "    return round(percent_score,2)\n",
    "    \n",
    "    \n",
    "trump_vs_obama = similarity('donald_speech.txt','obama_speech.txt')\n",
    "\n",
    "print('Trump and Obama speech has similarity score of {}%'.format(trump_vs_obama))\n",
    "\n",
    "   \n",
    "obama_vs_obama = similarity('obama_speech.txt','obama_speech.txt')\n",
    "\n",
    "print('Obama and Obama speech has similarity score of {}%'.format(obama_vs_obama))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Find the 10 most repeated words in the romeo_and_juliet.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 764),\n",
       " ('I', 550),\n",
       " ('and', 540),\n",
       " ('to', 522),\n",
       " ('of', 485),\n",
       " ('a', 453),\n",
       " ('in', 330),\n",
       " ('is', 322),\n",
       " ('my', 310),\n",
       " ('with', 274)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_common_words('romeo_and_juliet.txt',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Read the hacker news csv file and find out: a) Count the number of lines containing python or Python b) Count the number lines containing JavaScript, javascript or Javascript c) Count the number lines containing Java and not JavaScript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('hacker_news.csv') as f_obj:\n",
    "    csv_reader = csv.reader(f_obj, delimiter=',')\n",
    "    py_count = 0\n",
    "    js_count = 0\n",
    "    jar_n_js_count = 0\n",
    "    for row in csv_reader:\n",
    "        for item in row:\n",
    "            if 'python' in item.lower():\n",
    "                py_count += 1\n",
    "            if 'javascript' in item.lower():\n",
    "                js_count += 1\n",
    "            if ('java' in item.lower()) and ('javascript' not in item.lower()):\n",
    "                jar_n_js_count += 1\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines containing python or Python is 266\n",
      "The number of lines containing JavaScript, javascript or Javascript is 241\n",
      "The number of lines containing Java and not JavaScript is 96\n"
     ]
    }
   ],
   "source": [
    "# Count the number of lines containing python or Python\n",
    "\n",
    "print(\"The number of lines containing python or Python is {}\".format(py_count))\n",
    "\n",
    "# Count the number lines containing JavaScript, javascript or Javascript\n",
    "\n",
    "print(\"The number of lines containing JavaScript, javascript or Javascript is {}\".format(js_count))\n",
    "\n",
    "# Count the number lines containing Java and not JavaScript\n",
    "\n",
    "print(\"The number of lines containing Java and not JavaScript is {}\".format(jar_n_js_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
